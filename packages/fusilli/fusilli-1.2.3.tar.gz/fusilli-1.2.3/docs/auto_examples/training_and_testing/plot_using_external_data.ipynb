{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Using External Test Data\n\nLet's learn how to use external test data with Fusilli!\nSome guidance can also be found in the `Data Loading <data-loading>` section of the documentation.\n\nThe extra step that we need to take is to provide the paths to the test data files to the functions that create evaluation figures: :class:`~fusilli.eval.RealsVsPreds.from_new_data`, :class:`~fusilli.eval.ConfusionMatrix.from_new_data`, :class:`~fusilli.eval.ModelComparison.from_new_data`.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>It is not possible to use external test data with graph-based fusion models.</p></div>\n\n\nWe'll rush through the first few steps of the training and testing process, as they are covered in more detail in the other example notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nimport os\n\nfrom docs.examples import generate_sklearn_simulated_data\nfrom fusilli.data import prepare_fusion_data\nfrom fusilli.eval import RealsVsPreds, ModelComparison\nfrom fusilli.train import train_and_save_models\nfrom fusilli.utils.model_chooser import import_chosen_fusion_models\n\n# sphinx_gallery_thumbnail_number = -1\n\n\nmodel_conditions = {\n    \"class_name\": [\"ConcatTabularData\"],\n}\n\nfusion_models = import_chosen_fusion_models(model_conditions)\n\n# Regression task\nprediction_task = \"regression\"\n\n# Set the batch size\nbatch_size = 48\n\n# Setting output directories\noutput_paths = {\n    \"losses\": \"loss_logs/external_data\",\n    \"checkpoints\": \"checkpoints/external_data\",\n    \"figures\": \"figures/external_data\",\n}\n\nfor dir in output_paths.values():\n    os.makedirs(dir, exist_ok=True)\n\n# Clearing the loss logs directory (only for the example notebooks)\nfor dir in os.listdir(output_paths[\"losses\"]):\n    # remove files\n    for file in os.listdir(os.path.join(output_paths[\"losses\"], dir)):\n        os.remove(os.path.join(output_paths[\"losses\"], dir, file))\n    # remove dir\n    os.rmdir(os.path.join(output_paths[\"losses\"], dir))\n\ntabular1_path, tabular2_path = generate_sklearn_simulated_data(prediction_task,\n                                                               num_samples=500,\n                                                               num_tab1_features=10,\n                                                               num_tab2_features=20)\n\nexternal_tabular1_path, external_tabular2_path = generate_sklearn_simulated_data(prediction_task,\n                                                                                 num_samples=100,\n                                                                                 num_tab1_features=10,\n                                                                                 num_tab2_features=20,\n                                                                                 external=True)\ndata_paths = {\n    \"tabular1\": tabular1_path,\n    \"tabular2\": tabular2_path,\n    \"image\": \"\",\n}\n\nexternal_data_paths = {\n    \"tabular1\": external_tabular1_path,\n    \"tabular2\": external_tabular2_path,\n    \"image\": \"\",\n}\n\nfusion_model = fusion_models[0]\n\nprint(\"Method name:\", fusion_model.method_name)\nprint(\"Modality type:\", fusion_model.modality_type)\nprint(\"Fusion type:\", fusion_model.fusion_type)\n\n# Create the data module\ndm = prepare_fusion_data(prediction_task=prediction_task,\n                         fusion_model=fusion_model,\n                         data_paths=data_paths,\n                         output_paths=output_paths,\n                         batch_size=batch_size, )\n\n# train and test\ntrained_model = train_and_save_models(\n    data_module=dm,\n    fusion_model=fusion_model,\n    enable_checkpointing=True,\n    show_loss_plot=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating with validation data\nWe'll start by evaluating the model with the validation data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reals_preds_validation = RealsVsPreds.from_final_val_data(trained_model)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating with external data\nNow we'll evaluate the model with the external data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reals_preds_external = RealsVsPreds.from_new_data(trained_model,\n                                                  output_paths=output_paths,\n                                                  test_data_paths=external_data_paths)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Removing checkpoint files\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for dir in os.listdir(output_paths[\"checkpoints\"]):\n    # remove files\n    os.remove(os.path.join(output_paths[\"checkpoints\"], dir))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}