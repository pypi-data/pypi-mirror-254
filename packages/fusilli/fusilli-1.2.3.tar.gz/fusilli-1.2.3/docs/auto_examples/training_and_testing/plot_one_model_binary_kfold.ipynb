{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Binary Classification: Training a K-Fold Model\n\n\ud83d\ude80 In this tutorial, we'll explore binary classification using K-fold cross validation. \nWe'll show you how to train a fusion model using K-Fold cross-validation with multimodal tabular data. \nSpecifically, we're using the :class:`~.TabularCrossmodalMultiheadAttention` model.\n\n\nKey Features:\n\n- \ud83d\udce5 Importing a model based on its path.\n- \ud83e\uddea Training and testing a model with k-fold cross validation.\n- \ud83d\udcc8 Plotting the loss curves of each fold.\n- \ud83d\udcca Visualising the results of a single K-Fold model using the :class:`~.ConfusionMatrix` class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nimport os\n\nfrom docs.examples import generate_sklearn_simulated_data\nfrom fusilli.data import prepare_fusion_data\nfrom fusilli.eval import ConfusionMatrix\nfrom fusilli.train import train_and_save_models\n\n# sphinx_gallery_thumbnail_number = -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import the fusion model \ud83d\udd0d\nWe're importing only one model for this example, the :class:`~.TabularCrossmodalMultiheadAttention` model.\nInstead of using the :func:`~fusilli.utils.model_chooser.import_chosen_fusion_models` function, we're importing the model directly like with any other library method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fusilli.fusionmodels.tabularfusion.crossmodal_att import (\n    TabularCrossmodalMultiheadAttention,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Set the training parameters \ud83c\udfaf\nNow we're configuring our training parameters.\n\nFor training and testing, the necessary parameters are:\n- Paths to the input data files.\n- Paths to the output directories.\n- ``prediction_task``: the type of prediction to be performed. This is either ``regression``, ``binary``, or ``classification``.\n\nSome optional parameters are:\n\n- ``kfold``: a boolean of whether to use k-fold cross-validation (True) or not (False). By default, this is set to False.\n- ``num_folds``: the number of folds to use. It can't be ``k=1``.\n- ``wandb_logging``: a boolean of whether to log the results using Weights and Biases (True) or not (False). Default is False.\n- ``test_size``: the proportion of the dataset to include in the test split. Default is 0.2.\n- ``batch_size``: the batch size to use for training. Default is 8.\n- ``multiclass_dimensions``: the number of classes to use for multiclass classification. Default is None unless ``prediction_task`` is ``multiclass``.\n- ``max_epochs``: the maximum number of epochs to train for. Default is 1000.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Binary task (predicting a binary variable - 0 or 1)\nprediction_task = \"binary\"\n\n# Set the batch size\nbatch_size = 32\n\n# Enable k-fold cross-validation with k=5\nkfold = True\nnum_folds = 5\n\n# Setting output directories\noutput_paths = {\n    \"losses\": \"loss_logs/one_model_binary_kfold\",\n    \"checkpoints\": \"checkpoints/one_model_binary_kfold\",\n    \"figures\": \"figures/one_model_binary_kfold\",\n}\n\n# Create the output directories if they don't exist\nfor path in output_paths.values():\n    os.makedirs(path, exist_ok=True)\n\n# Clearing the loss logs directory (only for the example notebooks)\nfor dir in os.listdir(output_paths[\"losses\"]):\n    # remove files\n    for file in os.listdir(os.path.join(output_paths[\"losses\"], dir)):\n        os.remove(os.path.join(output_paths[\"losses\"], dir, file))\n    # remove dir\n    os.rmdir(os.path.join(output_paths[\"losses\"], dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generating simulated data \ud83d\udd2e\nTime to create some simulated data for our models to work their wonders on.\nThis function also simulated image data which we aren't using here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tabular1_path, tabular2_path = generate_sklearn_simulated_data(prediction_task,\n                                                               num_samples=500,\n                                                               num_tab1_features=10,\n                                                               num_tab2_features=20)\n\ndata_paths = {\n    \"tabular1\": tabular1_path,\n    \"tabular2\": tabular2_path,\n    \"image\": \"\",\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training the fusion model \ud83c\udfc1\nNow we're ready to train our model. We're using the :func:`~fusilli.train.train_and_save_models` function to train our model.\n\nFirst we need to create a data module using the :func:`~fusilli.data.prepare_fusion_data` function.\nThis function takes the following parameters:\n\n- ``prediction_task``: the type of prediction to be performed.\n- ``fusion_model``: the fusion model to be trained.\n- ``data_paths``: the paths to the input data files.\n- ``output_paths``: the paths to the output directories.\n\nThen we pass the data module and the fusion model to the :func:`~fusilli.train.train_and_save_models` function.\nWe're not using checkpointing for this example, so we set ``enable_checkpointing=False``. We're also setting ``show_loss_plot=True`` to plot the loss curves for each fold.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fusion_model = TabularCrossmodalMultiheadAttention\n\nprint(\"method_name:\", fusion_model.method_name)\nprint(\"modality_type:\", fusion_model.modality_type)\nprint(\"fusion_type:\", fusion_model.fusion_type)\n\ndm = prepare_fusion_data(prediction_task=prediction_task,\n                         fusion_model=fusion_model,\n                         data_paths=data_paths,\n                         output_paths=output_paths,\n                         kfold=kfold,\n                         num_folds=num_folds,\n                         batch_size=batch_size)\n\n# train and test\nsingle_model_list = train_and_save_models(\n    data_module=dm,\n    fusion_model=fusion_model,\n    enable_checkpointing=False,  # False for the example notebooks\n    show_loss_plot=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Plotting the results \ud83d\udcca\nNow we're ready to plot the results of our model.\nWe're using the :class:`~.ConfusionMatrix` class to plot the confusion matrix.\nWe're seeing each fold's confusion matrices separately on the right, and the confusion matrix created from the concatenated validation sets from each fold on the left.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "confusion_matrix_fig = ConfusionMatrix.from_final_val_data(\n    single_model_list\n)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}