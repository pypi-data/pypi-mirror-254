{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# General fusion template\n\nThis is a template for creating your own fusion model: operation-based, attention-based, or tensor-based.\nIf you want to implement a graph-based or subspace-based fusion model, please refer to the other templates. They require additional functions to be implemented.\n\nThere are two ways to create your own fusion model:\n\n1. You can use the preset layers in the :class:`~fusilli.fusion_models.base_model.ParentFusionModel` class. This is the easiest way to create your own fusion model. You can see an example of this in the :class:`~fusilli.fusion_models.concat_tabular_data.ConcatTabularData` class.\n2. You can create your own layers. This is the most flexible way to create your own fusion model.\n\nThe most important thing to remember is to output the final prediction as a list. This is because in subspace methods, the output is the label output and a reconstruction. This project's architecture is designed to be flexible enough to handle subspace methods too, hence the need for a list.\n\nHave fun creating your own fusion model!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\nimport torch\n\n# importing the parent fusion model class\nfrom fusilli.fusion_models.base_model import ParentFusionModel\n\n\nclass TemplateFusionModel(ParentFusionModel, nn.Module):\n    \"\"\"\n    Do you want to create your own multi-modal fusion model? This is the template for you!\n\n    Attributes\n    ----------\n    method_name : str\n        Name of the method.\n    modality_type : str\n        Type of modality.\n    fusion_type : str\n        Type of fusion.\n    pred_type : str\n        Type of prediction to be performed.\n    mod1_layers : dict\n        Dictionary containing the layers of the first modality.\n    mod2_layers : dict\n        Dictionary containing the layers of the second modality.\n    img_layers : dict\n        Dictionary containing the layers of the image modality.\n    fused_dim : int\n        Dimension of the fused layers.\n    fused_layers : nn.Sequential\n        Sequential layer containing the fused layers.\n    final_prediction : nn.Sequential\n        Sequential layer containing the final prediction layers. The final prediction layers\n        take in the number of features of the fused layers as input.\n\n    \"\"\"\n\n    # str: name of the method\n    method_name = \"Template fusion model\"\n    # str: modality type\n    modality_type = \"both_tab\"  # or \"tabular1\", \"tabular2\", \"both_tab\", \"tab_img\"\n    # str: fusion type\n    fusion_type = \"attention\"  # or \"operation\", \"tensor\", \"graph\", \"subspace\"\n\n    def __init__(self, pred_type, data_dims, params):\n        \"\"\"\n        Initialising the model.\n\n        Parameters\n        ----------\n\n        pred_type : str\n            Type of prediction to be performed.\n        data_dims : dict\n            Dictionary containing the dimensions of the data.\n        params : dict\n            Dictionary containing the parameters of the model.\n        \"\"\"\n        ParentFusionModel.__init__(self, pred_type, data_dims, params)\n        self.pred_type = pred_type\n\n        ################################\n        # SETTING THE UNI-MODAL LAYERS #\n        ################################\n        # You can either set the layers to be consistent with the rest of the library\n        # or you can set your own layers.\n\n        # USING PARENTFUSIONMODEL PRESET LAYERS\n        self.set_mod1_layers()  # set the layers for the first tabular modality\n        self.set_mod2_layers()  # set the layers for the second tabular modality\n        self.set_img_layers()  # set the layers for the image modality (if using)\n\n    def calc_fused_layers(self):\n        \"\"\"\n        Calculating the fused layers.\n\n        This is here so that if mod1_layers, mod2_layers, or img_layers are changed, the fused layers are automatically recalculated\n        to make sure that there aren't dimension mismatches.\n\n        Add any errors here if your method needs specific conditions to be met.\n        For example, mod1_layers and mod2_layers must have the same number of layers.\n\n        Returns\n        -------\n        None.\n\n        \"\"\"\n\n        ################################\n        #   SETTING THE FUSED LAYERS   #\n        ################################\n\n        # Setting a fused dimension: how many features are there after the fusion?\n        # For example, concatenating two tabular modalities after their respective uni-modal layers\n        # would be the sum of the number of output features.\n        # The linear layer we're looking for is the last linear layer (first element in final module_dict layer list.)\n        self.fused_dim = (\n            self.mod1_layers[-1][0].out_features + self.mod2_layers[-1][0].out_features\n        )\n\n        # Setting the fused layers: how do you want to fuse the modalities?\n        # Again, you can either set the layers to be consistent with the rest of the library\n        # or you can set your own layers.\n\n        # USING PARENTFUSIONMODEL PRESET LAYERS\n        self.set_fused_layers(self.fused_dim)\n\n        #################################\n        # SETTING THE FINAL PRED LAYERS #\n        #################################\n\n        # Setting the final prediction layers: how do you want to make the final prediction?\n        # Default input dim to final_pred_layers is 64, but you can change this in the function call.\n        self.set_final_pred_layers(input_dim=self.fused_dim)\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model. This is an example of a concatenation of feature maps!\n        Feel free to change this to suit your model - get creative!!\n\n        Parameters\n        ----------\n        x : list\n            List containing the input data.\n\n        Returns\n        -------\n        list\n            List containing the output of the model.\n        \"\"\"\n\n        x_tab1 = x[0]  # tabular1 data\n        x_tab2 = x[1]  # tabular2 data\n\n        # pass the data through the modality layers\n        for i, (k, layer) in enumerate(self.mod1_layers.items()):\n            x_tab1 = layer(x_tab1)\n            x_tab2 = self.mod2_layers[k](x_tab2)\n\n        # pass the data through the fused layers\n        out_fuse = torch.cat((x_tab1, x_tab2), dim=-1)\n        out_fuse = self.fused_layers(out_fuse)\n\n        # pass the data through the final prediction layers\n        out = self.final_prediction(out_fuse)\n\n        # You have to return the output of the model as a list.\n        # This is because in subspace methods, the output is the label output and a reconstruction.\n        # This project's architecture is designed to be flexible enough to handle subspace methods too, hence the list.\n\n        return [\n            out,\n        ]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}