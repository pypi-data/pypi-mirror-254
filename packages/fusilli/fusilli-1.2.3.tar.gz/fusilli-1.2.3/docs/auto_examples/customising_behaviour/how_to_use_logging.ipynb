{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# How to use Weights and Biases Logging with Fusilli\n\nWhen running fusilli, if ``params[\"log\"] = True``, fusilli will log the training and validation behaviour to Weights and Biases. This is done by using the ``wandb`` library.\n\nWeights and Biases is a free tool that allows you to track your machine learning experiments. To use fusilli with Weights and Biases, you will need to create a Weights and Biases account and log into it. You can do this by following the instructions [here](https://docs.wandb.ai/quickstart).\n\nMore info on how fusilli uses WandB can be found in the function :func:`~fusilli.utils.training_utils.set_logger`, but basically:\n\n#. If ``params[\"log\"] = True``, fusilli will log the training and validation behaviour to Weights and Biases. If ``params[\"log\"] = False``, fusilli will plot the loss curves using matplotlib and save as png files locally.\n#. Fusilli will create a project in your WandB account with the name ``params[\"project_name\"]``. If this project already exists, fusilli will use it. If it doesn't, fusilli will create it. If ``params[\"project_name\"]`` is not specified, fusilli will create a project with the name ``\"fusilli\"``.\n#. If you're rerunning fusion models with different parameters, these runs will be grouped by the fusion model's name.\n#. Each run is tagged with the modality type and fusion type of the fusion model by default, but you can add your own tags by specifying ``extra_log_string_dict`` into :func:`~fusilli.train.train_and_save_models`.\n#. If you're using k-fold cross validation, each fold will be logged as a separate run grouped by the fusion model's name, and tagged with the current fold number.\n\n\nNow I'll show you an example of specifying ``extra_log_string_dict`` into :func:`~fusilli.train.train_and_save_models` if I wanted to run :class:`~.EdgeCorrGNN` fusion model with :attr:`~.EdgeCorrGNN.dropout_prob` as 0.2 and I wanted to log this to Weights and Biases.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>For more info on modifying the models in fusilli (such as changing the dropout probability in :class:`~.EdgeCorrGNN`), see `modifying-models`.</p></div>\n\n```python\n# importing data and fusion models etc.\n\nfusion_model = EdgeCorrGNN\n\nmodification = {\n    \"EdgeCorrGNN\": {\n        \"dropout_prob\": 0.2\n    }\n}\n\nextra_string_for_wandb = {\"dropout_prob\": 0.5}\n\ntrained_model = train_and_save_models(\n    datamodule=datamodule,\n    params=params,\n    fusion_model=fusion_model,\n    extra_log_string_dict=extra_string_for_wandb,\n    layer_mods=modification\n)\n```\nWhen I train this and look at weights and biases, the run will be called ``EdgeCorrGNN_dropout_prob_0.2`` and will be tagged with ``dropout_prob_0.5``.\n\n\n**What if you're not using Weights and Biases?**\n\nIf you're not using Weights and Biases, fusilli will plot loss curves and save them as png files locally. Instead of the WandB project name having the extra user-specified tags, the png file name will have the extra user-specified tags. For example, if I was running the same fusion model as above, but I wasn't using Weights and Biases, the png file name would be ``EdgeCorrGNN_dropout_prob_0.2.png`` and would be saved in ``params[\"loss_fig_path\"]``.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}