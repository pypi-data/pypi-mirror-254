{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# How to create your own fusion model: a general template\n\nI want to create my own fusion model! Does this sound like you? Then this is the template for you! \u2728\u2728\u2728\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>**Is this the correct template for you?**\n\n    If you want to implement a graph-based or subspace-based fusion model, please refer to the other templates.\n\n    You'll know if you need to use them if the input into the model you're implementing can't be represented as a tuple of tensors of the original input data (modality1, modality2).\n\n    For example:\n\n    * If you're implementing a graph-based fusion model, the input into the model is a graph, not a tuple of tensors.\n    * If you're implementing a subspace-based fusion model, the input into the model might be a latent space from a VAE trained on the original input data, not the original input data itself.</p></div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Importing the libraries\nLet's import the libraries we need to create our model. Because we're using PyTorch, we need to import the PyTorch libraries\nas well as the :class:`~.ParentFusionModel` class and functions to help with checking model conditions and validity in the :mod:`~.utils.check_model_validity` module.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\nimport torch\n\n# importing the parent fusion model class\nfrom fusilli.fusionmodels.base_model import ParentFusionModel\n\n# importing functions to help with checking model conditions and validity\nfrom fusilli.utils import check_model_validity\n\n\n# sphinx_gallery_thumbnail_path = '_static/ConcatTabularFeatureMaps.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Creating the model structure\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Step 2.1: Creating the class**\nLet's create the class for our model. We'll call it ``TemplateFusionModel``. This class will inherit from the\n:class:`~.ParentFusionModel` class and the :class:`~torch.nn.Module` class. This is because we want to inherit the\nmethods and attributes from the :class:`~.ParentFusionModel` class and we want to make sure that our model is a\nPyTorch model.\n\n:class:`~.ParentFusionModel` has 3 input arguments:\n\n* ``prediction_task`` : a string telling the model what type of prediction to perform. This is specified by the user in their python script or notebook.\n* ``data_dims`` : a list of the dimensions of the input data. This is calculated by :func:`~fusilli.data.prepare_fusion_data`.\n* ``multiclass_dimensions`` : the number of classes in a multiclass classification task. This is specified by the user in their python script or notebook. It is ``None`` if the task is not a multiclass classification task.\n\nThese input arguments have to be passed into the ``__init__()`` function of our fusion model. When running this library, this is done automatically for you in\nthe :func:`~fusilli.train.train_and_save_models` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class TemplateFusionModel(ParentFusionModel, nn.Module):\n    def __init__(self, prediction_task, data_dims, multiclass_dimensions):\n        ParentFusionModel.__init__(self, prediction_task, data_dims, multiclass_dimensions)\n\n    def forward(self, x):\n        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Step 2.2: Setting the model attributes**\nEach model has to have the following attributes at the class level (i.e. outside of the ``__init__()`` function and accessable without having to call ``TemplateFusionModel()``):\n\n* ``method_name`` : a string of the method name. This can be a better description of the method than the class name. For example, the class name might be ``ConcatTabularData`` but the method name might be ``Concatenation of tabular data``.\n* ``modality_type`` : a string containing the type of modality, which is one of the following: ``tabular1``, ``tabular2``, ``tabular_tabular``, ``tabular_image``, ``img``.\n* ``fusion_type`` : a string containing the type of fusion, which is one of the following: ``operation``, ``attention``, ``tensor``, ``graph``, ``subspace``. To find out more about the different types of fusion, please refer to the `fusion-model-explanations` section.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The comment above the class attributes lets the attributes be documented automatically by Sphinx. This is why the comment is formatted in a specific way.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class TemplateFusionModel(ParentFusionModel, nn.Module):\n    # str: name of the method\n    method_name = \"Template fusion model\"\n    # str: modality type\n    modality_type = \"tabular_tabular\"  # or \"tabular1\", \"tabular2\", \"tabular_tabular\", \"tabular_image\", \"img\"\n    # str: fusion type\n    fusion_type = \"attention\"  # or \"operation\", \"tensor\", \"graph\", \"subspace\"\n\n    def __init__(self, prediction_task, data_dims, multiclass_dimensions):\n        ParentFusionModel.__init__(self, prediction_task, data_dims, multiclass_dimensions)\n\n    def forward(self, x):\n        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Step 2.3: Setting the model layers**\nNow we need to set the layers of the model. This is done in the ``__init__()`` function of the model.\n\nThere are two ways to set the layers of the model:\n\n1. You can use the preset layers in the :class:`~.ParentFusionModel` class. This is the easiest way to create your own fusion model. You can see an example of this in the :class:`~fusilli.fusionmodels.tabularfusion.concat_data.ConcatTabularData` class.\n2. You can create your own layers. This is the most flexible way to create your own fusion model but it might mean that the model is less easily comparible to other models in the library.\n\nLet's go through each of these methods in turn.\n\n**Method 1: Using preset layers**\n\nLet's say we want to use the preset layers in the :class:`~.ParentFusionModel` class. We can do this by calling the following functions:\n\n* :func:`~.set_mod1_layers` : sets the layers for the first tabular modality as ``self.mod1_layers``.\n* :func:`~.set_mod2_layers` : sets the layers for the second tabular modality as ``self.mod2_layers``.\n* :func:`~.set_img_layers` : sets the layers for the image modality as ``self.img_layers``.\n* :func:`~.set_fused_layers` : sets some layers that take place after the fusion of the modalities (may not be applicable for all fusion models) as ``self.fused_layers``. For example, if you're concatenating feature maps from multiple modalities, the fused layers would be the layers after the concatenation and before the prediction.\n* :func:`~.set_final_pred_layers` : sets the layers for the final prediction as ``self.final_predction``. We must set ``self.prediction_task`` to the ``prediction_task`` input argument of the ``__init__()`` function before calling this function. This is because the final prediction layers depend on the type of prediction we want to perform.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Calling ``self.set_mod1_layers()`` by itself is equivalent to calling ``self.mod1_layers = self.set_mod1_layers()``. This is because the ``set_mod1_layers()`` function assigns the layers to the ``mod1_layers`` attribute in :class:`~.ParentFusionModel`, which our model inherits from.\n  The same is true for the other :class:`~.ParentFusionModel` functions: ``set_mod2_layers()``, ``set_img_layers()``, ``set_fused_layers()``, and ``set_final_pred_layers()``.</p></div>\n\n**Method 2: Creating your own layers**\n\nThis is simply done by creating a dictionary of layers and assigning it to the ``mod1_layers`` attribute of the model. For example:\n\n```python\nself.mod1_layers = nn.ModuleDict({\n    \"linear1\": nn.Linear(10, 20),\n    \"linear2\": nn.Linear(20, 30),\n    \"linear3\": nn.Linear(30, 40),\n})\n```\nLet's create our own layers for our model. We'll use the preset layers in the :class:`~.ParentFusionModel` class and make a tabular-tabular fusion model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class TemplateFusionModel(ParentFusionModel, nn.Module):\n    # str: name of the method\n    method_name = \"Template fusion model\"\n    # str: modality type\n    modality_type = \"tabular_tabular\"  # or \"tabular1\", \"tabular2\", \"tabular_tabular\", \"tabular_image\", \"img\"\n    # str: fusion type\n    fusion_type = \"attention\"  # or \"operation\", \"tensor\", \"graph\", \"subspace\"\n\n    def __init__(self, prediction_task, data_dims, multiclass_dimensions):\n        ParentFusionModel.__init__(self, prediction_task, data_dims, multiclass_dimensions)\n\n        self.prediction_task = prediction_task\n\n        self.set_mod1_layers()  # set the layers for the first tabular modality\n        self.set_mod2_layers()  # set the layers for the second tabular modality\n\n        # Calculate the \"fused_dim\": how many features are there after the fusion? For example:\n        mod1_layers_output_dim = self.mod1_layers[-1][0].out_features\n        mod2_layers_output_dim = self.mod2_layers[-1][0].out_features\n        self.fused_dim = (\n                mod1_layers_output_dim + mod2_layers_output_dim\n        )\n\n        self.set_fused_layers(\n            fused_dim=self.fused_dim)  # set the fused layers with an input dimension of self.fused_dim\n\n        self.set_final_pred_layers(\n            input_dim=64)  # set the final prediction layers with an input dimension of 64 (output dimension of fused layers)\n\n    def forward(self, x):\n        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Setting up model to be modifiable\n\nGreat! We've set up the model structure. Now we need to make sure that the model is modifiable.\n\nIn order to do this, we need to make sure that the model can handle if parts of it are changed.\nFor example, if the number of output nodes in the final layers of ``self.mod1_layers`` is changed,\nthe layers after it have to be recalculated so that there isn't a dimension mismatch.\n\nWe can do this by creating a function called ``calc_fused_layers()``. This function should be called at the end of the ``__init__()`` function and should\ncontain all the checks that need to be performed to make sure that the modifications made to the model are valid.\nThe function ``set_final_pred_layers()`` should be moved into this function since it relies on the outputs of modifiable layers before it.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>This function must be called ``calc_fused_layers()``.\n  This is because the function is called whenever a modification is made to the model in :func:`~.modify_model_architecture`.\n\n  If you call the function something else, it won't be called when a modification is made to the model and the model won't be modifiable.</p></div>\n\n**The steps we are taking here are:**\n\n1. Create a function called ``calc_fused_layers()``.\n2. Recalculate ``self.fused_dim`` in the ``calc_fused_layers()`` function to update the fused dimension if the model is modified.\n3. Add a check in the ``calc_fused_layers()`` function with :func:`~.check_model_validity.check_fused_layers` to make sure that the fused layers are valid. This changes the first fused layer to have the correct input dimension (if it's not already correct) and outputs the output dimension of the fused layers.\n4. Move the ``set_final_pred_layers()`` function into the ``calc_fused_layers()`` function and use the input from the fused layers to set the final prediction layers.\n5. Call the ``calc_fused_layers()`` function at the end of the ``__init__()`` function.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If calculating ``self.fused_dim`` is complicated, you can create a separate function called ``get_fused_dim()`` and call it in ``__init__()`` and in ``calc_fused_layers()``.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class TemplateFusionModel(ParentFusionModel, nn.Module):\n    # str: name of the method\n    method_name = \"Template fusion model\"\n    # str: modality type\n    modality_type = \"tabular_tabular\"  # or \"tabular1\", \"tabular2\", \"tabular_tabular\", \"tabular_image\", \"img\"\n    # str: fusion type\n    fusion_type = \"attention\"  # or \"operation\", \"tensor\", \"graph\", \"subspace\"\n\n    def __init__(self, prediction_task, data_dims, multiclass_dimensions):\n        ParentFusionModel.__init__(self, prediction_task, data_dims, multiclass_dimensions)\n\n        self.prediction_task = prediction_task\n\n        self.set_mod1_layers()  # set the layers for the first tabular modality\n        self.set_mod2_layers()  # set the layers for the second tabular modality\n\n        self.get_fused_dim()\n\n        self.set_fused_layers(\n            fused_dim=self.fused_dim)  # set the fused layers with an input dimension of self.fused_dim\n\n        self.calc_fused_layers()  # calculate the fused layers to make sure there aren't dimension mismatches\n\n    def get_fused_dim(self):\n        mod1_layers_output_dim = self.mod1_layers[-1][0].out_features\n        mod2_layers_output_dim = self.mod2_layers[-1][0].out_features\n        self.fused_dim = (\n                mod1_layers_output_dim + mod2_layers_output_dim\n        )\n\n    def calc_fused_layers(self):\n        self.get_fused_dim()\n\n        self.fused_layers, out_dim = check_model_validity.check_fused_layers(\n            self.fused_layers, self.fused_dim\n        )\n\n        self.set_final_pred_layers(\n            input_dim=out_dim)  # set the final prediction layers with the output dimension of fused layers\n\n    def forward(self, x):\n        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Defining the forward function\nLet's define the forward function of our model. This is where we define how the data flows through the model. This example is concatenating the feature maps of two tabular modalities.\n\n**The input into the forward function is either:**\n\n* a tuple of tensors (modality1, modality2) if there are two modalities\n* a tensor of the original input data (if there is only one modality). This is probably not applicable to your model but it might be for a graph- or subspace-based fusion model.\n\n**The output of the forward function is a list containing the output of the model.**\nThis is because some of the models in Fusilli output reconstructed data as well as the prediction, and this library is designed to handle this by all outputs either being a list of length 1 or 2.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def forward(self, x):\n    x_tab1 = x[0]  # tabular1 data\n    x_tab2 = x[1]  # tabular2 data\n\n    # Passing the data through the modality layers\n    for i, (k, layer) in enumerate(self.mod1_layers.items()):\n        x_tab1 = layer(x_tab1)\n        x_tab2 = self.mod2_layers[k](x_tab2)\n\n    # Concatenating the feature maps from the two modalities\n    out_fuse = torch.cat((x_tab1, x_tab2), dim=-1)\n    # Passing the fused data through the fused layers\n    out_fuse = self.fused_layers(out_fuse)\n\n    # Passing the data through the final prediction layers\n    out = self.final_prediction(out_fuse)\n\n    return [\n        out,\n    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Adding checks\nLet's add some checks to make sure that the model components and the input data are what we expect them to be.\nWe've already added checks to the ``self.fused_layers`` attribute in the ``calc_fused_layers()`` function.\n**The checks we are adding are:**\n\n* Checking that the input data is a tuple of tensors with :func:`~.check_model_validity.check_model_input`.\n* Checking that the modality layers are a :class:`~torch.nn.ModuleDict` with :func:`~.check_model_validity.check_dtype`.\n\nYour model might have more specific checks, such as checking that your modality layers have the same number of layers if that is a requirement of your model.\n\nAt the beginning of the ``forward()`` function, we add the following check:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def forward(self, x):\n    check_model_validity.check_model_input(x)\n\n    # rest of forward function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At the beginning of the ``calc_fused_layers()`` function, we add the following checks:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def calc_fused_layers(self):\n    check_model_validity.check_dtype(self.mod1_layers, nn.ModuleDict, \"mod1_layers\")\n    check_model_validity.check_dtype(self.mod2_layers, nn.ModuleDict, \"mod2_layers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we were using images, we would also add the following check at the beginning of the ``calc_fused_layers()`` function which checks that the image layers are a :class:`~torch.nn.ModuleDict` and that the image dimension is correct\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def calc_fused_layers(self):\n    check_model_validity.check_img_dim(self.img_layers, self.img_dim, \"img_layers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Adding documentation\nAll that's left is to add documentation to the model. This is done by adding a docstring to the class and to the ``__init__()`` function.\nThe docstring for the class should contain the following:\n\n* A description of the model.\n* The attributes of the model (all the attributes that start with ``self.``).\n\nThe docstring for the ``__init__()`` function and other functions in the model (``calc_fused_layers()``, etc)should contain the following:\n\n* A description of the function.\n* The input arguments of the function.\n* The output of the function.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The docstrings are formatted in a specific way so that they can be documented automatically by Sphinx.</p></div>\n\nLet's add documentation to our model and see it all come together!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class TemplateFusionModel(ParentFusionModel, nn.Module):\n    \"\"\" Description of the model.\n\n    More information about the model, perhaps a link to a paper, etc.\n\n    Attributes\n    ----------\n    method_name : str\n        Name of the method.\n    modality_type : str\n        Type of modality.\n    fusion_type : str\n        Type of fusion.\n    prediction_task : str\n        Type of prediction to be performed.\n    mod1_layers : dict\n        Dictionary containing the layers of the first modality.\n    mod2_layers : dict\n        Dictionary containing the layers of the second modality.\n    fused_dim : int\n        Dimension of the fused layers.\n    fused_layers : nn.Sequential\n        Sequential layer containing the fused layers.\n    final_prediction : nn.Sequential\n        Sequential layer containing the final prediction layers. The final prediction layers\n        take in the number of features of the fused layers as input.\n\n    \"\"\"\n\n    # str: name of the method\n    method_name = \"Template fusion model\"\n    # str: modality type\n    modality_type = \"tabular_tabular\"  # or \"tabular1\", \"tabular2\", \"tabular_tabular\", \"tabular_image\", \"img\"\n    # str: fusion type\n    fusion_type = \"attention\"  # or \"operation\", \"tensor\", \"graph\", \"subspace\"\n\n    def __init__(self, prediction_task, data_dims, multiclass_dimensions):\n        \"\"\"\n        Initialising the model.\n\n        Parameters\n        ----------\n\n        prediction_task : str\n            Type of prediction to be performed.\n        data_dims : list\n            List containing the dimensions of the data. This is calculated by :func:`~fusilli.data.prepare_fusion_data`.\n        multiclass_dimensions : dict\n            Dictionary containing the parameters of the model. This is specified by the user in their python script or notebook.\n        \"\"\"\n        ParentFusionModel.__init__(self, prediction_task, data_dims, multiclass_dimensions)\n        self.prediction_task = prediction_task\n\n        self.set_mod1_layers()  # set the layers for the first tabular modality\n        self.set_mod2_layers()  # set the layers for the second tabular modality\n\n        self.get_fused_dim()\n\n        self.set_fused_layers(\n            fused_dim=self.fused_dim)  # set the fused layers with an input dimension of self.fused_dim\n\n        self.calc_fused_layers()  # calculate the fused layers to make sure there aren't dimension mismatches\n\n    def get_fused_dim(self):\n        \"\"\"\n        Get the number of input features of the fused layers.\n        \"\"\"\n        mod1_layers_output_dim = self.mod1_layers[-1][0].out_features\n        mod2_layers_output_dim = self.mod2_layers[-1][0].out_features\n        self.fused_dim = (\n                mod1_layers_output_dim + mod2_layers_output_dim\n        )\n\n    def calc_fused_layers(self):\n        \"\"\"\n        Calculates the fused layers.\n        \"\"\"\n        check_model_validity.check_dtype(self.mod1_layers, nn.ModuleDict, \"mod1_layers\")\n        check_model_validity.check_dtype(self.mod2_layers, nn.ModuleDict, \"mod2_layers\")\n\n        self.get_fused_dim()\n\n        self.fused_layers, out_dim = check_model_validity.check_fused_layers(\n            self.fused_layers, self.fused_dim\n        )\n\n        self.set_final_pred_layers(\n            input_dim=out_dim)  # set the final prediction layers with the output dimension of fused layers\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Parameters\n        ----------\n        x : tuple\n         Tuple containing the input data.\n\n        Returns\n        -------\n        list\n         List containing the output of the model.\n        \"\"\"\n        check_model_validity.check_model_input(x)\n\n        x_tab1 = x[0]  # tabular1 data\n        x_tab2 = x[1]  # tabular2 data\n\n        # Passing the data through the modality layers\n        for i, (k, layer) in enumerate(self.mod1_layers.items()):\n            x_tab1 = layer(x_tab1)\n            x_tab2 = self.mod2_layers[k](x_tab2)\n\n        # Concatenating the feature maps from the two modalities\n        out_fuse = torch.cat((x_tab1, x_tab2), dim=-1)\n        # Passing the fused data through the fused layers\n        out_fuse = self.fused_layers(out_fuse)\n\n        # Passing the data through the final prediction layers\n        out = self.final_prediction(out_fuse)\n\n        return [\n            out,\n        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I hope this template has been helpful! If you have any questions, please feel free to ask in the GitHub Discussions page.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}