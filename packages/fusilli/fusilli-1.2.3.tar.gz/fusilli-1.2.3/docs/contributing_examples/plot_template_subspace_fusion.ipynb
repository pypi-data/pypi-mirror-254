{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fusion Model Template: Subspace-based Fusion\n\nThis tutorial will show you how to create a subspace-based fusion model.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>I recommend looking at `how_to_contribute_a_template_other_fusion` before looking at this template, as I will skip over some of the details that are covered in that template (particularly regarding documentation and idiosyncrasies of the fusion model template).</p></div>\n\nThere are **two** types of subspace-based fusion models in this library:\n\n1. A model that has subspace methods trained **before** the main prediction model. An example of this is :class:`~fusilli.fusionmodels.tabularfusion.denoise_tab_img_maps.DAETabImgMaps`. This works by training the subspace method first, then using the output of the subspace method as the input to the main prediction model.\n2. A model that has subspace methods (such as an autoencoder) trained **simultaneously** with the main prediction model. An example of this is :class:`~fusilli.fusionmodels.tabularimagefusion.concat_img_latent_tab_doubleloss.ConcatImgLatentTabDoubleLoss`. This works by implementing a joint loss function that combines the loss of the subspace method and the loss of the main prediction model.\n\nWe will look at how to create both of these types of models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Option 1: Simultaneously-trained subspace-based fusion model\n\nThere are two differences between this type of model and the general template in `how_to_contribute_a_template_other_fusion`:\n\n* Must have the attribute ``self.custom_loss`` which is the loss function used to train the subspace method (e.g. the MSELoss for an autoencoder).\n* Must output the subspace method's output in the ``forward`` method as the second list element e.g. output = [prediction, reconstruction]\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>Using custom loss is currently only implemented if the **second modality is the reconstructed modality**, e.g. the image in tabular-image fusion, or the second tabular modality in tabular-tabular fusion.\n\n   The reconstruction shape **must** be the same as the input shape.</p></div>\n\nHere is a diagram of an example of a simultaneously-trained subspace-based fusion model:\n\n<img src=\"file://../_static/simultaneous_train.png\">\n\nAnd here is the code for the model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport torch\nimport torch.nn as nn\nimport lightning.pytorch as pl\nfrom fusilli.fusionmodels.base_model import ParentFusionModel\n\n\nclass TemplateSubspaceFusionModel(ParentFusionModel):\n    \"\"\"\n    Template for a subspace-based fusion model that has the subspace method trained before the main prediction model.\n    \"\"\"\n\n    method_name = \"Template Subspace Fusion Model\"\n    modality_type = \"tabular_tabular\"\n    fusion_type = \"subspace\"\n\n    def __init__(self, prediction_task, data_dims, multiclass_dimensions):\n        super().__init__(prediction_task, data_dims, multiclass_dimensions)\n\n        # nn.Module: Subspace method for the second modality\n        self.subspace_method_downsample = nn.Sequential(\n            nn.Linear(750, 480),\n            nn.ReLU(),\n            nn.Linear(480, 220),\n            nn.ReLU(),\n            nn.Linear(220, 88),\n        )\n        self.subspace_method_upsample = nn.Sequential(\n            nn.Linear(88, 220),\n            nn.ReLU(),\n            nn.Linear(220, 480),\n            nn.ReLU(),\n            nn.Linear(480, 750),\n        )\n\n        # nn.Module: Prediction layers.\n        # Concatenating the subspace method's output with the first tabular modality data\n        self.pred_model = nn.Sequential(\n            nn.Linear(88 + data_dims[0], 50),\n            nn.ReLU(),\n            nn.Linear(50, 25),\n            nn.ReLU(),\n            nn.Linear(25, 5),\n        )\n\n        self.set_final_pred_layers(input_dim=5)\n\n        # nn.Module: Custom loss function for the reconstruction\n        self.custom_loss = nn.MSELoss()\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model.\n\n        Parameters\n        ----------\n        x : list\n            List of modalities.\n\n        Returns\n        -------\n        list\n            List of outputs from the model.\n        \"\"\"\n        tabular_1 = x[0]\n        tabular_2 = x[1]\n\n        # get the subspace method's output\n        subspace_output = self.subspace_method_downsample(tabular_2)\n        subspace_reconstruction = self.subspace_method_upsample(subspace_output)\n\n        # get the prediction model's output (concatenating the subspace method's output with the tabular data)\n        out_fused = self.pred_model(torch.cat([tabular_1, subspace_output]))\n\n        prediction = self.final_prediction(out_fused)\n\n        # returning the subspace method's output as the second list element\n        return [prediction, subspace_reconstruction]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we've got the basic structure of the model, there is one additional thing to consider:\n\n**Can the model be modified?**\n\nFor the most user flexibility, the model attributes should be able to be modified (such as the subspace method layers) and the model should be able to recalculate the layers of the model if the attributes are modified.\n\n**For more information on this, see Step 3 in `how_to_contribute_a_template_other_fusion`.**\n\n-----\n\n## Option 2: Pre-trained subspace-based fusion model\n\nThis section will show how to create susbapce-based fusion model which involves one or more models that have to be pre-trained.\n\nThe ``.py`` file that contains the whole fusion model must have the following three things:\n\n1. A PyTorch Lightning module which contains the subspace model architecture, e.g. ``class TemplateSubspaceModel(pl.LightningModule):``\n2. A class with the methods ``load_ckpt``, ``train``, and ``convert_to_latent``, which are used to load the pre-trained model, train a latent space, and convert data to a latent space respectively. These are called when the data for the fusion model is loaded in :func:`~.prepare_fusion_data`.\n3. The fusion model class which contains the main prediction model architecture, e.g. ``class TemplateSubspaceFusionModel(ParentFusionModel, nn.Module):`` Similar to a general fusion model, this must have the methods ``__init__``, ``calc_fused_layers``, and ``forward``.\n\nThis is a diagram of an example of a pre-trained subspace-based fusion model:\n\n<img src=\"file://../_static/pretrain_subspace_diagram.png\">\n\nLet's go through each of these in detail.\n\n### Step 1: Create the PyTorch Lightning subspace model\n\nMight be useful to familiarise yourself with the pytorch lightning module first.\n\nMethods that must have specific names:\n\n* ``__init__``: initialising with input parameters ``data_dims``, which is a list of the data dimensions of the input data.\n* ``forward``: the forward pass of the model. Takes ``x`` as input. Must be modifiable (see Step 3 in `how_to_contribute_a_template_other_fusion`) for details.\n* ``training_step``: the training step of the model. Takes ``batch`` and ``batch_idx`` as input.\n* ``validation_step``: the validation step of the model. Takes ``batch`` and ``batch_idx`` as input.\n* ``configure_optimizers``: the optimiser of the model.\n\nMethods that can have any name:\n\n* A method that gets the latent space of the model from the input data, e.g. ``encode_image`` for an autoencoder with an image input. In our example, this is ``get_latent_rep``.\n\nHere's an example of a model with a simple 2-layer autoencoder to get the latent space of the tabular data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class TemplateSubspaceModel(pl.LightningModule):\n\n    def __init__(self, data_dims):\n        super(TemplateSubspaceModel, self).__init__()\n\n        self.tab_shape = data_dims[0]\n\n        self.encoder = nn.Linear(self.tab_shape, 50)\n        self.decoder = nn.Linear(50, self.tab_shape)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n\n        return x\n\n    def training_step(self, batch, batch_idx):\n        output = self(batch)\n\n        loss = nn.MSELoss()(output, batch)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        output = self(batch)\n\n        loss = nn.MSELoss()(output, batch)\n\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=0.001)\n\n    def get_latent_rep(self, x):\n        return self.encoder(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: create the class with the methods ``load_ckpt``, ``train``, and ``convert_to_latent``\n\n**Must have** a class attribute (defined before the ``__init__`` method) ``subspace_models``: a list of the subspace model classes.\n\nFor our example, ``subspace_methods = [TemplateSubspaceModel]``.\n\nMust have the following methods:\n\n* ``__init__``: initialising with input parameters ``datamodule``, ``k``, ``max_epochs``, and ``train_subspace``. For more detailed documentation, see :class:`~.concat_img_latent_tab_subspace_method`.\n* ``load_ckpt``: loading the pre-trained model. Takes ``checkpoint_path`` as input.\n* ``train``: training the latent space. Takes ``train_dataset`` and ``val_dataset`` as input.\n* ``convert_to_latent``: converting the data to a latent space. Takes ``test_dataset`` as input.\n\nLet's create the ``__init__`` method first.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The ``datamodule`` parameter is the data module that is created in :func:`~.prepare_fusion_data`. This is used to get the data for the subspace method.</p></div>\n\n The input arguments that we need are ``datamodule``, ``k``, ``max_epochs``, and ``train_subspace``. These are all passed to this method during :func:`~.prepare_fusion_data`, so we need to make sure that we have these as input arguments.\n\nA couple things need to happen in the ``__init__`` method:\n\n1. Set the ``datamodule`` attribute to the input ``datamodule``. This is accessed during utilities relating to checkpointing.\n2. The subspace model, ``TemplateSubspaceModel``, must be initialised. This is done by calling ``self.subspace_models[0]``.\n3. If ``train_subspace`` is ``True``, then the subspace model must be trained. This means that we need to:\n\n  a. Get the appropriate checkpoint path for the subspace model. This is done by calling :func:`~.get_checkpoint_filenames_for_subspace_models`.\n  b. Initialise a PyTorch Lightning trainer using :func:`~.init_trainer`.\n\nHere's an example of the ``__init__`` method:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from fusilli.utils.training_utils import get_checkpoint_filenames_for_subspace_models, init_trainer\n\n\nclass TemplateSubspaceMethod:\n    subspace_models = [TemplateSubspaceModel]\n\n    def __init__(self, datamodule, k=None, max_epochs=1000, train_subspace=True):\n        self.datamodule = datamodule\n\n        self.autoencoder = self.subspace_models[0](datamodule.data_dims)\n\n        if train_subspace:\n            autoencoder_ckpt_list = get_checkpoint_filenames_for_subspace_models(self, k)\n            # returns a list of checkpoint paths for the subspace model (length 1 for our example)\n\n            self.trainer = init_trainer(\n                logger=None,  # no logger for the subspace models\n                output_paths=self.datamodule.output_paths,  # pass in the output paths dict stored in the datamodule\n                max_epochs=max_epochs,  # max_epochs is an input argument\n                checkpoint_filename=autoencoder_ckpt_list[0],  # checkpoint_filename is the first element of the list\n            )\n\n    # %%\n    # Now let's create the ``load_ckpt`` method. This is called when we have already trained the subspace model and we are passing new data through the model, such as in :func:`~.RealsVsPreds.from_new_data`.\n    #\n    # The ``state_dict`` of the model must be loaded from the checkpoint.\n\n    # ... continuing from the previous code snippet ...\n\n    def load_ckpt(self, checkpoint_path):\n        self.autoencoder.load_state_dict(torch.load(checkpoint_path[0])[\"state_dict\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Onto the ``train`` method.\n\nThe following must happen in this method:\n\n1. The data will be input as train and validation datasets and these need to be converted to dataloaders.\n2. The model will be trained and tested by calling ``.fit`` and ``.validate()`` on the trainer.\n3. The latent space of the train data will be calculated by calling ``.get_latent_rep`` on the model.\n4. The new train data will be returned as a list of length 2: ``[the predictive train features, pandas dataframe of the train labels]``.\n\n.. warning ::\n\n   Be careful not to get your train and test data mixed up! Both have to be converted to the latent space but only the train dataset should be used in ``.fit()``\n\nHere's an example of the ``train`` method for our example, where the second tabular modality is being converted to a latent space to be our new second tabular modality:\ne.g. [tab1, tab2] -> [tab1, tab2_latent]\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# imports for the train method\nimport pandas as pd\nfrom torch.utils.data import DataLoader\n\n\n# ... continuing from the previous code snippet ...\ndef train(self, train_dataset, val_dataset):\n    tabular1_train_features = train_dataset[:][0]\n    tabular2_train_features = train_dataset[:][1]\n    train_labels = train_dataset[:][2]\n\n    tabular1_val_features = val_dataset[:][0]\n    tabular2_val_features = val_dataset[:][1]\n    val_labels = val_dataset[:][2]\n\n    # setting dataloaders for the train and validation datasets of tabular 2\n    train_dataloader = DataLoader(\n        tabular2_train_features,\n        batch_size=16,  # customise\n        shuffle=False,\n    )\n    val_dataloader = DataLoader(\n        tabular2_val_features,\n        batch_size=16,  # customise\n        shuffle=False,\n    )\n\n    # training the model\n    self.trainer.fit(self.autoencoder, train_dataloader, val_dataloader)\n\n    # validating the model\n    self.trainer.validate(self.autoencoder, val_dataloader)\n\n    # setting the model to evaluation mode\n    self.autoencoder.eval()\n\n    # getting the latent space of the train data\n    tabular2_train_features_latent = self.autoencoder.get_latent_rep(tabular2_train_features)\n\n    # returning the new train data\n    new_pred_features = [tabular1_train_features, tabular2_train_features_latent]\n    label_dataframe = pd.DataFrame(\n        train_labels, columns=[\"prediction_label\"]\n    )\n\n    return [new_pred_features, label_dataframe]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let's create the ``convert_to_latent`` method.\nThis is similar to the ``train`` method, except that we don't need to train the model, only convert the input data to the already-trained latent space.\n\nWe will return the list, like in the ``train`` method, but this time there will be an additional element in the list: the list of data dimensions ``[tab1_dim, tab2_dim, img_dim]``.\n\nIn our example's case, the data dimensions would be ``[tab1_dim, tab2_latent_dim, None]``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ... continuing from the previous code snippet ...\ndef convert_to_latent(self, test_dataset):\n    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: create the fusion model class\n\nVery similar to the general fusion model template in `how_to_contribute_a_template_other_fusion`.\n\nBiggest difference is that we have an additional class-level attribute ``subspace_method``, which points to the class that we created in Step 2.\n\nThis fusion model will use the data from ``convert_to_latent`` in Step 2, not the original input data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class TemplateSubspaceFusionModel(ParentFusionModel, nn.Module):\n    method_name = \"Template Subspace Fusion Model - with pre-trained subspace method\"\n    modality_type = \"tabular_tabular\"\n    fusion_type = \"subspace\"\n\n    # class-level attribute pointing to the subspace method class\n    subspace_method = TemplateSubspaceMethod\n\n    def __init__(self, prediction_task, data_dims, multiclass_dimensions):\n        ParentFusionModel.__init__(self, prediction_task, data_dims, multiclass_dimensions)\n\n        # nn.Module: Prediction layers concatenating the latent space with the tabular data\n        self.pred_model = nn.Sequential(\n            nn.Linear(data_dims[0] + data_dims[1], 50),\n            nn.ReLU(),\n            nn.Linear(50, 25),\n            nn.ReLU(),\n            nn.Linear(25, 5),\n        )\n\n        # setting the final prediction layers based on the prediction type\n        self.set_final_pred_layers(input_dim=5)\n\n    def forward(self, x):\n        tabular_1 = x[0]\n        tabular_2 = x[1]\n\n        # get the prediction model's output (concatenating the latent space with the tabular data)\n        out_fused = self.pred_model(torch.cat([tabular_1, tabular_2], dim=1))\n\n        # get the final prediction\n        prediction = self.final_prediction(out_fused)\n\n        # returning the prediction as the first list element\n        return [prediction, ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As with the simultaneously-trained subspace-based fusion model, we need to think about:\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>**Can the model be modified?**\n\n  For the most user flexibility, the model attributes should be able to be modified (such as the subspace method layers) and the model should be able to recalculate the layers of the model if the attributes are modified.\n\n  For more information on this, see Step 3 in `how_to_contribute_a_template_other_fusion`.</p></div>\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}