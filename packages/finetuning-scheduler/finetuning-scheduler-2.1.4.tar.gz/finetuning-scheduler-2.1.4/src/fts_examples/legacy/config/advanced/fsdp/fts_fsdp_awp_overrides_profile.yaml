model:
  class_path: fts_examples.legacy.fts_fsdp_superglue.RteBoolqModuleFSDP
trainer:
  limit_train_batches: 7
  max_epochs: 4
  devices: 2
  callbacks:
  - class_path: finetuning_scheduler.FinetuningScheduler
    init_args:
      ft_schedule: ./config/RteBoolqModule_ft_schedule_deberta_base_fsdp.yaml
      max_depth: 2
      strategy_adapter_cfg:
        awp_overrides: ["model.pooler.dense", "model.classifier"]
  - class_path: finetuning_scheduler.FTSCheckpoint
    init_args:
      save_top_k: 1
      monitor: val_loss
      verbose: true
  - class_path: finetuning_scheduler.FTSEarlyStopping
    init_args:
      monitor: val_loss
      min_delta: 0.001
      patience: 2 # limited patience for example
      verbose: false
      mode: min
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: lightning_logs
      name: fts_fsdp_awp_overrides_profile
  profiler:
    class_path: fts_examples.legacy.fts_fsdp_superglue.ExtendedPyTorchProfiler
    init_args:
      filename: fts_fsdp_awp_text_profile
      max_name_column_width: 100
      sort_by_key: cuda_time_total
      schedule_cfg:
        # note, there is currently (as of lightning 1.9.0 release) an open issue regarding superfluous profiler messages
        # https://github.com/pytorch/pytorch/issues/91886
        skip_first: 20  # comment if you want to profile the first fine-tuning phase instead of the final one
        wait: 1
        warmup: 1
        active: 3
    dict_kwargs:
      with_stack: true
      profile_memory: true
      record_shapes: true
      row_limit: 50
  strategy:
    class_path: lightning.pytorch.strategies.FSDPStrategy
    init_args:
      cpu_offload: false
      activation_checkpointing:
      - transformers.models.deberta_v2.modeling_deberta_v2.DebertaV2Layer
      auto_wrap_policy: fts_examples.legacy.fts_fsdp_superglue.deberta_awp  # comment to generate debugging demo
      # auto_wrap_policy: fts_examples.legacy.fts_fsdp_superglue.degenerate_deberta_awp  # uncomment for debugging demo
