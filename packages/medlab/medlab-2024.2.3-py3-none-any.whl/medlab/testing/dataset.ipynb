{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证数据集配置 示例代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../jmseg')\n",
    "from jmseg.registry import build_dataloader_from_cfg, build_dataset_from_cfg\n",
    "from mmengine.config import Config\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: ../jmseg/configs/_base_/datasets/drive.py): {'dataset_type': 'Dataset', 'data_root': 'data/DRIVE', 'in_channels': 3, 'num_classes': 1, 'crop_size': (128, 128), 'inferer': {'type': 'SlidingWindowInferer', 'roi_size': (128, 128), 'sw_batch_size': 4}, 'metrics': [{'type': 'DiceMetric', 'include_background': False, 'reduction': 'mean'}, {'type': 'ConfusionMatrixMetric', 'include_background': False, 'reduction': 'mean', 'metric_name': 'accuracy'}], 'train_pipeline': [{'type': 'LoadImaged', 'keys': ['images', 'labels'], 'reader': 'PILReader', 'ensure_channel_first': True, 'image_only': True}, {'type': 'ScaleIntensityd', 'keys': ['images', 'labels']}, {'type': 'RandZoomd', 'keys': ['images', 'labels'], 'prob': 0.5, 'min_zoom': 0.8, 'max_zoom': 1.2, 'mode': ('bilinear', 'nearest')}, {'type': 'RandRotated', 'keys': ['images', 'labels'], 'prob': 0.5, 'range_x': 0.3, 'mode': ('bilinear', 'nearest')}, {'type': 'RandAxisFlipd', 'keys': ['images', 'labels'], 'prob': 0.5}, {'type': 'RandCropByPosNegLabeld', 'keys': ['images', 'labels'], 'label_key': 'labels', 'spatial_size': (128, 128), 'pos': 1, 'neg': 1, 'num_samples': 4, 'image_key': 'images', 'image_threshold': 0}, {'type': 'RandShiftIntensityd', 'keys': ['images'], 'offsets': 0.1, 'prob': 0.5}], 'val_pipeline': [{'type': 'LoadImaged', 'keys': ['images', 'labels'], 'reader': 'PILReader', 'ensure_channel_first': True}, {'type': 'ScaleIntensityd', 'keys': ['images', 'labels']}], 'train_dataloader': {'type': 'DataLoader', 'batch_size': 4, 'num_workers': 8, 'dataset': {'type': 'Dataset', 'img_suffix': '_training.tif', 'label_suffix': '_manual1.gif', 'data_root': 'data/DRIVE', 'img_dir': 'training/images', 'label_dir': 'training/1st_manual', 'subset': 'train', 'test_size': 0.2, 'random_state': 0, 'pipeline': [{'type': 'LoadImaged', 'keys': ['images', 'labels'], 'reader': 'PILReader', 'ensure_channel_first': True, 'image_only': True}, {'type': 'ScaleIntensityd', 'keys': ['images', 'labels']}, {'type': 'RandZoomd', 'keys': ['images', 'labels'], 'prob': 0.5, 'min_zoom': 0.8, 'max_zoom': 1.2, 'mode': ('bilinear', 'nearest')}, {'type': 'RandRotated', 'keys': ['images', 'labels'], 'prob': 0.5, 'range_x': 0.3, 'mode': ('bilinear', 'nearest')}, {'type': 'RandAxisFlipd', 'keys': ['images', 'labels'], 'prob': 0.5}, {'type': 'RandCropByPosNegLabeld', 'keys': ['images', 'labels'], 'label_key': 'labels', 'spatial_size': (128, 128), 'pos': 1, 'neg': 1, 'num_samples': 4, 'image_key': 'images', 'image_threshold': 0}, {'type': 'RandShiftIntensityd', 'keys': ['images'], 'offsets': 0.1, 'prob': 0.5}]}}, 'val_dataloader': {'type': 'DataLoader', 'batch_size': 1, 'num_workers': 8, 'dataset': {'type': 'Dataset', 'img_suffix': '_training.tif', 'label_suffix': '_manual1.gif', 'data_root': 'data/DRIVE', 'img_dir': 'training/images', 'label_dir': 'training/1st_manual', 'subset': 'val', 'test_size': 0.2, 'random_state': 0, 'pipeline': [{'type': 'LoadImaged', 'keys': ['images', 'labels'], 'reader': 'PILReader', 'ensure_channel_first': True}, {'type': 'ScaleIntensityd', 'keys': ['images', 'labels']}]}}, 'test_dataloader': {'type': 'DataLoader', 'batch_size': 1, 'num_workers': 8, 'dataset': {'type': 'Dataset', 'img_suffix': '_training.tif', 'label_suffix': '_manual1.gif', 'data_root': 'data/DRIVE', 'img_dir': 'training/images', 'label_dir': 'training/1st_manual', 'subset': 'val', 'test_size': 0.2, 'random_state': 0, 'pipeline': [{'type': 'LoadImaged', 'keys': ['images', 'labels'], 'reader': 'PILReader', 'ensure_channel_first': True}, {'type': 'ScaleIntensityd', 'keys': ['images', 'labels']}]}}, 'test_cfg': {'output_ext': '.png', 'scale': 255}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 配置文件路径\n",
    "config_path = '../jmseg/configs/_base_/datasets/drive.py'\n",
    "cfg = Config.fromfile(config_path)\n",
    "cfg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 检查img和label路径是否有误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取配置中的dataloader配置\n",
    "train_dataloader = cfg.get('train_dataloader', None)\n",
    "assert train_dataloader is not None\n",
    "\n",
    "# 获取dataloader中的dataset配置\n",
    "train_dataset = train_dataloader.get('dataset', None)\n",
    "assert train_dataset is not None\n",
    "\n",
    "# 获取dataset中的pipline配置\n",
    "pipline = train_dataset.pop('pipeline', None)\n",
    "# 获取dataset的data_root\n",
    "data_root = train_dataset.pop('data_root', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/DRIVE\n"
     ]
    }
   ],
   "source": [
    "# 查看data_root\n",
    "print(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/DRIVE\n"
     ]
    }
   ],
   "source": [
    "# 如果data_root是相对路径，因为本代码路径在testing目录下, 相对路径会出现错误，需要进行更改\n",
    "if not data_root.startswith('/'):\n",
    "    data_root = os.path.join('../', data_root)\n",
    "    print(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新data_root，并将pipeline置空，先检查路径，后续再检查pipeline是否正确\n",
    "train_dataset.update(dict(data_root=data_root, pipeline=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset_from_cfg(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/DRIVE/training/images/31_training.tif ../data/DRIVE/training/1st_manual/31_manual1.gif\n",
      "../data/DRIVE/training/images/38_training.tif ../data/DRIVE/training/1st_manual/38_manual1.gif\n",
      "../data/DRIVE/training/images/27_training.tif ../data/DRIVE/training/1st_manual/27_manual1.gif\n",
      "../data/DRIVE/training/images/34_training.tif ../data/DRIVE/training/1st_manual/34_manual1.gif\n",
      "../data/DRIVE/training/images/25_training.tif ../data/DRIVE/training/1st_manual/25_manual1.gif\n",
      "../data/DRIVE/training/images/23_training.tif ../data/DRIVE/training/1st_manual/23_manual1.gif\n",
      "../data/DRIVE/training/images/26_training.tif ../data/DRIVE/training/1st_manual/26_manual1.gif\n",
      "../data/DRIVE/training/images/35_training.tif ../data/DRIVE/training/1st_manual/35_manual1.gif\n",
      "../data/DRIVE/training/images/30_training.tif ../data/DRIVE/training/1st_manual/30_manual1.gif\n",
      "../data/DRIVE/training/images/28_training.tif ../data/DRIVE/training/1st_manual/28_manual1.gif\n",
      "../data/DRIVE/training/images/37_training.tif ../data/DRIVE/training/1st_manual/37_manual1.gif\n",
      "../data/DRIVE/training/images/32_training.tif ../data/DRIVE/training/1st_manual/32_manual1.gif\n",
      "../data/DRIVE/training/images/24_training.tif ../data/DRIVE/training/1st_manual/24_manual1.gif\n",
      "../data/DRIVE/training/images/21_training.tif ../data/DRIVE/training/1st_manual/21_manual1.gif\n",
      "../data/DRIVE/training/images/36_training.tif ../data/DRIVE/training/1st_manual/36_manual1.gif\n",
      "../data/DRIVE/training/images/33_training.tif ../data/DRIVE/training/1st_manual/33_manual1.gif\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i['images'], i['labels'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 检查pipeline是否存在问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.update(dict(pipeline=pipline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset_from_cfg(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'images': tensor([[[-0.0293, -0.0332, -0.0187,  ..., -0.0243, -0.0326, -0.0253],\n",
      "         [ 0.0949,  0.0420,  0.0064,  ..., -0.0279, -0.0320, -0.0253],\n",
      "         [ 0.2331,  0.1483,  0.0640,  ..., -0.0263, -0.0275, -0.0253],\n",
      "         ...,\n",
      "         [ 0.7292,  0.7364,  0.7508,  ..., -0.0191, -0.0202, -0.0256],\n",
      "         [ 0.7321,  0.7403,  0.7454,  ..., -0.0207, -0.0195, -0.0134],\n",
      "         [ 0.7409,  0.7479,  0.7596,  ..., -0.0250, -0.0242, -0.0163]],\n",
      "\n",
      "        [[-0.0306, -0.0200, -0.0232,  ..., -0.0243, -0.0326, -0.0264],\n",
      "         [-0.0519, -0.0402, -0.0365,  ..., -0.0298, -0.0330, -0.0272],\n",
      "         [-0.0567, -0.0567, -0.0492,  ..., -0.0341, -0.0317, -0.0298],\n",
      "         ...,\n",
      "         [ 0.3057,  0.3142,  0.3173,  ..., -0.0253, -0.0244, -0.0316],\n",
      "         [ 0.3049,  0.3139,  0.3079,  ..., -0.0285, -0.0236, -0.0268],\n",
      "         [ 0.3081,  0.3118,  0.3124,  ..., -0.0294, -0.0282, -0.0229]],\n",
      "\n",
      "        [[-0.0308, -0.0287, -0.0304,  ..., -0.0243, -0.0399, -0.0326],\n",
      "         [-0.0294, -0.0234, -0.0293,  ..., -0.0288, -0.0403, -0.0334],\n",
      "         [-0.0561, -0.0494, -0.0413,  ..., -0.0302, -0.0387, -0.0360],\n",
      "         ...,\n",
      "         [ 0.1559,  0.1577,  0.1651,  ..., -0.0222, -0.0314, -0.0385],\n",
      "         [ 0.1577,  0.1640,  0.1616,  ..., -0.0246, -0.0307, -0.0313],\n",
      "         [ 0.1630,  0.1655,  0.1674,  ..., -0.0320, -0.0357, -0.0296]]]), 'labels': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.]]])}, {'images': tensor([[[0.0039, 0.0039, 0.0039,  ..., 0.8992, 0.9077, 0.9379],\n",
      "         [0.0029, 0.0029, 0.0029,  ..., 0.9163, 0.9332, 0.9599],\n",
      "         [0.0030, 0.0030, 0.0030,  ..., 0.9331, 0.9445, 0.9746],\n",
      "         ...,\n",
      "         [0.0072, 0.0072, 0.0072,  ..., 0.0292, 0.0246, 0.0307],\n",
      "         [0.0082, 0.0082, 0.0082,  ..., 0.0280, 0.0249, 0.0272],\n",
      "         [0.0089, 0.0089, 0.0089,  ..., 0.0295, 0.0257, 0.0272]],\n",
      "\n",
      "        [[0.0039, 0.0039, 0.0039,  ..., 0.3312, 0.3458, 0.3576],\n",
      "         [0.0029, 0.0029, 0.0029,  ..., 0.3364, 0.3601, 0.3724],\n",
      "         [0.0030, 0.0030, 0.0030,  ..., 0.3633, 0.3844, 0.3834],\n",
      "         ...,\n",
      "         [0.0029, 0.0029, 0.0029,  ..., 0.0292, 0.0246, 0.0307],\n",
      "         [0.0029, 0.0029, 0.0029,  ..., 0.0280, 0.0249, 0.0272],\n",
      "         [0.0027, 0.0027, 0.0027,  ..., 0.0295, 0.0257, 0.0272]],\n",
      "\n",
      "        [[0.0039, 0.0039, 0.0039,  ..., 0.1952, 0.2031, 0.2285],\n",
      "         [0.0029, 0.0029, 0.0029,  ..., 0.2065, 0.2062, 0.2332],\n",
      "         [0.0022, 0.0022, 0.0022,  ..., 0.2230, 0.2142, 0.2264],\n",
      "         ...,\n",
      "         [0.0033, 0.0033, 0.0033,  ..., 0.0292, 0.0246, 0.0307],\n",
      "         [0.0042, 0.0042, 0.0042,  ..., 0.0280, 0.0249, 0.0272],\n",
      "         [0.0050, 0.0050, 0.0050,  ..., 0.0295, 0.0257, 0.0272]]]), 'labels': tensor([[[0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])}, {'images': tensor([[[0.8001, 0.8200, 0.8285,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         [0.8520, 0.8664, 0.8729,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         [0.8753, 0.8999, 0.9143,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         ...,\n",
      "         [0.1312, 0.1312, 0.1324,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         [0.1312, 0.1304, 0.1300,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         [0.1312, 0.1300, 0.1276,  ..., 0.0959, 0.0959, 0.0959]],\n",
      "\n",
      "        [[0.4247, 0.4413, 0.4454,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         [0.4642, 0.4778, 0.4779,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         [0.4972, 0.5148, 0.5170,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         ...,\n",
      "         [0.1273, 0.1261, 0.1245,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         [0.1273, 0.1261, 0.1247,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         [0.1273, 0.1261, 0.1237,  ..., 0.0959, 0.0959, 0.0959]],\n",
      "\n",
      "        [[0.3170, 0.3444, 0.3442,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         [0.3608, 0.3797, 0.3750,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         [0.3758, 0.3927, 0.3900,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         ...,\n",
      "         [0.1194, 0.1219, 0.1284,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         [0.1194, 0.1195, 0.1210,  ..., 0.0959, 0.0959, 0.0959],\n",
      "         [0.1194, 0.1182, 0.1158,  ..., 0.0959, 0.0959, 0.0959]]]), 'labels': tensor([[[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])}, {'images': tensor([[[1.0802, 1.0802, 1.0802,  ..., 1.0802, 1.0802, 1.0802],\n",
      "         [1.0802, 1.0802, 1.0802,  ..., 1.0802, 1.0802, 1.0802],\n",
      "         [1.0802, 1.0802, 1.0802,  ..., 1.0802, 1.0802, 1.0802],\n",
      "         ...,\n",
      "         [0.8203, 0.8212, 0.8154,  ..., 0.7927, 0.7832, 0.7779],\n",
      "         [0.7962, 0.7953, 0.8011,  ..., 0.7870, 0.7742, 0.7783],\n",
      "         [0.7930, 0.7770, 0.7783,  ..., 0.7815, 0.7713, 0.7707]],\n",
      "\n",
      "        [[0.5562, 0.5469, 0.5509,  ..., 0.5613, 0.5872, 0.6151],\n",
      "         [0.5456, 0.5543, 0.5495,  ..., 0.5332, 0.5456, 0.5569],\n",
      "         [0.5547, 0.5513, 0.5529,  ..., 0.5575, 0.5761, 0.5578],\n",
      "         ...,\n",
      "         [0.4326, 0.4393, 0.4381,  ..., 0.4734, 0.4734, 0.4763],\n",
      "         [0.4131, 0.4282, 0.4378,  ..., 0.4780, 0.4782, 0.4814],\n",
      "         [0.3914, 0.4157, 0.4356,  ..., 0.4727, 0.4765, 0.4787]],\n",
      "\n",
      "        [[0.3178, 0.3127, 0.3273,  ..., 0.3236, 0.3410, 0.3573],\n",
      "         [0.3106, 0.3207, 0.3278,  ..., 0.3302, 0.3355, 0.3455],\n",
      "         [0.3220, 0.3236, 0.3226,  ..., 0.3636, 0.3635, 0.3614],\n",
      "         ...,\n",
      "         [0.3066, 0.3018, 0.2900,  ..., 0.3435, 0.3385, 0.3345],\n",
      "         [0.2864, 0.2942, 0.2928,  ..., 0.3474, 0.3348, 0.3426],\n",
      "         [0.2752, 0.2758, 0.2952,  ..., 0.3438, 0.3299, 0.3378]]]), 'labels': tensor([[[0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])}]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['images', 'labels'])\n",
      "torch.Size([3, 128, 128])\n",
      "torch.Size([1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# 训练dataloader的pipeline中的LoadImaged指定了image_only参数为True，所以只有iamges, labels两个key\n",
    "# 如果image_only为False，则会有images_meta和labels_meta信息\n",
    "print(dataset.__getitem__(0)[0].keys())\n",
    "print(dataset.__getitem__(0)[0]['images'].shape)\n",
    "print(dataset.__getitem__(0)[0]['labels'].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 检查dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = build_dataloader_from_cfg(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    # 输出TypedStorage is deprecated...警告是由于monai1.1.0和pytorch2.0.0版本不兼容导致的，可以忽略\n",
    "    print(batch['images'].shape)\n",
    "    print(batch['labels'].shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
